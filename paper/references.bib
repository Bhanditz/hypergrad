@article{bengio2000gradient,
  title={Gradient-based optimization of hyperparameters},
  author={Bengio, Yoshua},
  journal={Neural computation},
  volume={12},
  number={8},
  pages={1889--1900},
  year={2000},
  publisher={MIT Press}
}

@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT Press}
}

@Article{ lecun1989backpropagation,
	title = "Backpropagation applied to handwritten zip code recognition",
	author = "Y. LeCun and B. Boser and J. S. Denker and D. Henderson and R. E. Howard and W. Hubbard and L. D. Jackel",
	journal = "Neural Computation",
	volume = "1",
	pages = "541--551",
	year = "1989",
	publisher = "Massachusetts Institute of Technology"
}

@inproceedings{snoek2012practical,
  title={Practical {B}ayesian Optimization of Machine Learning Algorithms},
  author={Snoek, Jasper and Larochelle, Hugo and Ryan P. Adams},
  booktitle={Advances in Neural Information Processing Systems 25},
  pages={2960--2968},
  year={2012}
}

@Article{ salakhutdinov2008using,
	author = "Ruslan Salakhutdinov and Geoffrey Hinton",
	title = "Using Deep Belief Nets to Learn Covariance Kernels for {G}aussian Processes",
	journal = "Advances in Neural information processing systems",
	volume = "20",
	pages = "1249--1256",
	year = "2008",
	booktitle = "Advances in Neural Information Processing Systems"
}

@Book{ rasmussen38gaussian,
	author = "Carl E. Rasmussen and Christopher K.I. Williams",
	title = "{G}aussian Processes for Machine Learning",
	publisher = "The MIT Press, Cambridge, MA, USA",
	year = "2006"
}

@Article{ bengio1994learning,
	title = "Learning long-term dependencies with gradient descent is difficult",
	author = "Yoshua Bengio and Patrice Simard and Paolo Frasconi",
	journal = "Neural Networks, IEEE Transactions on",
	volume = "5",
	number = "2",
	pages = "157--166",
	year = "1994",
	publisher = "IEEE"
}

@Article{ pascanu2012understanding,
	title = "Understanding the exploding gradient problem",
	author = "Razvan Pascanu and Tomas Mikolov and Yoshua Bengio",
	journal = "arXiv preprint arXiv:1211.5063",
	year = "2012"
}

@article{lecun1995convolutional,
  title={Convolutional networks for images, speech, and time series},
  author={LeCun, Yann and Bengio, Yoshua},
  journal={The handbook of brain theory and neural networks},
  volume={3361},
  year={1995},
  publisher={MIT Press}
}

@article{chapelle2002choosing,
  title={Choosing multiple parameters for support vector machines},
  author={Chapelle, Olivier and Vapnik, Vladimir and Bousquet, Olivier and Mukherjee, Sayan},
  journal={Machine learning},
  volume={46},
  number={1-3},
  pages={131--159},
  year={2002},
  publisher={Springer}
}

@incollection{larsen1998adaptive,
  title={Adaptive regularization in neural network modeling},
  author={Larsen, Jan and Svarer, Claus and Andersen, Lars Nonboe and Hansen, Lars Kai},
  booktitle={Neural Networks: Tricks of the Trade},
  pages={113--132},
  year={1998},
  publisher={Springer}
}

@article{deepGPVar14,
title={Nested Variational Compression in Deep {G}aussian Processes},
author={James Hensman and Neil D. Lawrence},
journal={arXiv preprint arXiv:1412.1370},
year={2014}
}

@article{schaul2012no,
  title={No more pesky learning rates},
  author={Schaul, Tom and Zhang, Sixin and LeCun, Yann},
  journal={arXiv preprint arXiv:1206.1106},
  year={2012}
}

@article{Adam14,
title={Adam: A Method for Stochastic Optimization},
author={Diederik Kingma and Jimmy Ba},
journal={arXiv preprint arXiv:1412.6980},
year={2014}
}

@article{Adasecant14,
title={{ADASECANT}: Robust Adaptive Secant Method for Stochastic Gradient},
author={Caglar Gulcehre and Yoshua Bengio},
journal={arXiv preprint arXiv:1412.7419},
year={2014}
}

@article{Hotswap14,
title={Hot Swapping for Online Adaptation of Optimization Hyperparameters},
author={Kevin Bache and Dennis DeCoste and Padhraic Smyth},
journal={arXiv preprint arXiv:1412.6599},
year={2014}
}

