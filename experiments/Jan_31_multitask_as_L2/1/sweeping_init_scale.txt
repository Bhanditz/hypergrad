. . . . . . . . {'N_layers': 2, 'OrderedDict': <class 'collections.OrderedDict'>, 'rms_prop': <function rms_prop at 0x7f0b4e6f8b18>, 'it': <module 'itertools' (built-in)>, 'seed': 2, 'alpha': 1.0, 'partial': <type 'functools.partial'>, 'sgd': <function differentiable_fun at 0x7f0b4e6f8938>, 'N_scripts_per_iter': 1, 'dictslice': <function dictslice at 0x7f0b4970e1b8>, 'N_iters': 100, 'kylist': <function differentiable_fun at 0x7f0b4c9960c8>, 'plot': <function plot at 0x7f0b4e6f8cf8>, 'omniglot': <module 'hypergrad.omniglot' from '/home/dougal/Dropbox/proj/hypergrad/hypergrad/omniglot.pyc'>, '__package__': None, 'RandomState': <class 'hypergrad.util.RandomState'>, 'make_nn_funs': <function make_nn_funs at 0x7f0b46dedb18>, 'np': <module 'numpy' from '/usr/local/lib/python2.7/dist-packages/numpy/__init__.pyc'>, '__doc__': None, 'defaultdict': <type 'collections.defaultdict'>, 'log_L2_init': -4.0, 'run': <function run at 0x7f0b4e6f8c80>, 'getval': <function getval at 0x7f0b4c97f0c8>, '__builtins__': <module '__builtin__' (built-in)>, '__file__': 'experiment.py', 'batch_size': 200, 'results': ['log_initialization_scale = -6.0   train_loss: 2.63451584824, validation_loss 2.92502917899', 'log_initialization_scale = -5.0   train_loss: 2.25254085453, validation_loss 2.67628819382', 'log_initialization_scale = -4.0   train_loss: 1.97533802427, validation_loss 2.51852256049', 'log_initialization_scale = -3.0   train_loss: 1.81030584647, validation_loss 2.45073899832', 'log_initialization_scale = -2.0   train_loss: 1.73718908058, validation_loss 2.43952922705', 'log_initialization_scale = -1.0   train_loss: 1.72600728701, validation_loss 2.44298198168', 'log_initialization_scale = 0.0   train_loss: 1.77099200751, validation_loss 2.46433397305', 'log_initialization_scale = 1.0   train_loss: 1.94282048295, validation_loss 2.55839150275'], 'N_scripts': 1, 'pickle': <module 'pickle' from '/usr/lib/python2.7/pickle.pyc'>, '__name__': '__main__', 'log_initialization_scale': -2.0, 'layer_sizes': [784, 100, 55], 'VectorParser': <class 'hypergrad.nn_utils.VectorParser'>, 'beta': 0.9, 'script_corr': 0.0, 'grad': <function grad at 0x7f0b4c9ee938>}
--------------------------------------------------------------------------------
log_initialization_scale = -6.0   train_loss: 2.63451584824, validation_loss 2.92502917899
log_initialization_scale = -5.0   train_loss: 2.25254085453, validation_loss 2.67628819382
log_initialization_scale = -4.0   train_loss: 1.97533802427, validation_loss 2.51852256049
log_initialization_scale = -3.0   train_loss: 1.81030584647, validation_loss 2.45073899832
log_initialization_scale = -2.0   train_loss: 1.73718908058, validation_loss 2.43952922705
log_initialization_scale = -1.0   train_loss: 1.72600728701, validation_loss 2.44298198168
log_initialization_scale = 0.0   train_loss: 1.77099200751, validation_loss 2.46433397305
log_initialization_scale = 1.0   train_loss: 1.94282048295, validation_loss 2.55839150275
